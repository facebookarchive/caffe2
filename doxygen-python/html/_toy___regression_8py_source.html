<!-- HTML header for doxygen 1.8.14-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Caffe2 - Python API: caffe2/python/tutorials/py_gen/Toy_Regression.py Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="icon" href="/static/favicon.png" type="image/x-icon">
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="stylesheet.css" rel="stylesheet" type="text/css" />
<link href="main.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo" width="56"><a href="/"><img alt="Logo" src="Caffe2-with-name-55-tall.png"/></a></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Caffe2 - Python API
   </div>
   <div id="projectbrief">A deep learning, cross platform ML framework</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="namespaces.html"><span>Packages</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li><a href="/doxygen-c/html/classes.html"><span>C++&#160;API</span></a></li>
      <li><a href="/doxygen-python/html/annotated.html"><span>Python&#160;API</span></a></li>
      <li><a href="https://github.com/caffe2/caffe2"><span>GitHub</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_20697b8f204bdfcab31e6b1a416f3ab8.html">caffe2</a></li><li class="navelem"><a class="el" href="dir_f4fda25fc5253eea1ed54677ae5fa2de.html">python</a></li><li class="navelem"><a class="el" href="dir_97a8e4938fab5a0841bdb9cd8076985e.html">tutorials</a></li><li class="navelem"><a class="el" href="dir_38e1d20e965e77ed1a3671bbc2942034.html">py_gen</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Toy_Regression.py</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">#########################################################</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment">#</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment"># DO NOT EDIT THIS FILE. IT IS GENERATED AUTOMATICALLY. #</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment"># PLEASE LOOK INTO THE README FOR MORE INFORMATION.     #</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment">#</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment">#########################################################</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="comment"># coding: utf-8</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="comment"># # Tutorial 2. A Simple Toy Regression</span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="comment"># This is a quick example showing how one can use the concepts introduced in [Tutorial 1: Basics](https://caffe2.ai/docs/tutorial-basics-of-caffe2.html) to do regression. This tutorial is split up into two parts. **Part I** is a more verbose example of creating and training a polynomial regression model and **Part II** is a concise linear regression example.</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="comment"># ## Part I: Polynomial Regression</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="comment"># The problem we are dealing with is a relatively simple one and involves a one-dimensional input $x$ and one-dimensional output $y.$ Because we seek a second order polynomial as the regression model, the weight vector will contain two weights ($\beta_2$ and $\beta_1$) and there will be a single bias ($\beta_0$) or intercept. The desired solution is of the form:</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="comment"># $$y = \beta_2x^2 + \beta_1x + \beta_0$$</span></div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="comment"># For this tutorial, we will generate and format an arbitrary set of input data that possess a strong second order polynomial relationship. We will then construct the model, specify the training algorithm, perform the training, and finally look at the results.</span></div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="comment"># In[1]:</span></div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="keyword">from</span> __future__ <span class="keyword">import</span> division</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="keyword">from</span> <a class="code" href="namespacecaffe2_1_1python.html">caffe2.python</a> <span class="keyword">import</span> workspace, brew, optimizer</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="keyword">from</span> <a class="code" href="namespacecaffe2_1_1python_1_1model__helper.html">caffe2.python.model_helper</a> <span class="keyword">import</span> ModelHelper</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;<span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="keyword">import</span> sklearn.datasets</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;<span class="comment"># ### Inputs</span></div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;<span class="comment"># Specify the input parameters of the regression model here including: number of samples in the input data, number of training iterations, learning rate of SGD algorithm, and the initial weights of the model</span></div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;<span class="comment"># In[2]:</span></div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;<span class="comment"># Number of training sample to generate</span></div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;num_samples = 200</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;<span class="comment"># Learning Rate of SGD algorithm</span></div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;learning_rate = .05</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;<span class="comment"># Number of iterations to train</span></div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;training_iters = 100</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;<span class="comment"># Initial model weights</span></div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;initial_weights = [0.,0.]</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;<span class="comment"># ### Create and Prepare the Dataset</span></div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;<span class="comment"># Now, we will create and prepare the dataset for use with the model. Note, we are just constructing numpy arrays here. Any other data can be used as long as it is shaped properly before being input into the model.</span></div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;<span class="comment"># In[3]:</span></div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;<span class="comment"># Create the original observations</span></div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;orig_X,_ = sklearn.datasets.make_regression(n_samples=num_samples,n_features=1,noise=5)</div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;poly = PolynomialFeatures(degree=2, include_bias=<span class="keyword">False</span>)</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;<span class="comment"># Transform the features into second order polynomial features</span></div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;xx_ = poly.fit_transform(orig_X)</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;<span class="comment"># Extract the predictors and the values from the manufactured data</span></div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;X = [i[0] <span class="keywordflow">for</span> i <span class="keywordflow">in</span> xx_]</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;Y_gt = [i[1] <span class="keywordflow">for</span> i <span class="keywordflow">in</span> xx_]</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;noise = np.random.uniform(size=(len(Y_gt)))</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;<span class="comment"># Add some noise to the ground truth values</span></div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;Y_gt += noise</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;<span class="comment"># Shape the ground truth values for use with the model</span></div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;Y_gt = np.reshape(Y_gt,(-1,1))</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;<span class="comment"># Format the input features. Recall, we accomplish polynomial regression by</span></div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;<span class="comment">#   including the original and the polynomial version of the predictors</span></div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;<span class="comment">#   as features of the model</span></div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;X = np.hstack((np.array(X).reshape(-1,1),np.array(X).reshape(-1,1)**2))</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;<span class="comment"># Print a sample of the input data. X is the list of 2-feature input observations </span></div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;<span class="comment">#   and Y is the list of ground truth values associated with each observation</span></div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;print(<span class="stringliteral">&quot;X Sample:\n{}&quot;</span>.format(X[:5]))</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;print(<span class="stringliteral">&quot;Y Sample:\n{}&quot;</span>.format(Y_gt[:5]))</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;<span class="comment"># Plot the input data</span></div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;plt.scatter([i[0] <span class="keywordflow">for</span> i <span class="keywordflow">in</span> X],Y_gt,label=<span class="stringliteral">&quot;original data&quot;</span>,color=<span class="stringliteral">&#39;b&#39;</span>)</div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;plt.xlabel(<span class="stringliteral">&quot;x&quot;</span>)</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;plt.ylabel(<span class="stringliteral">&quot;y&quot;</span>)</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;plt.title(<span class="stringliteral">&quot;Input Training Data&quot;</span>)</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;<span class="comment"># ### Create the Model</span></div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;<span class="comment"># #### Define the model architecture</span></div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;<span class="comment"># With our training data created and our second order polynomial assumption stated, we can now create a model to learn the regression line. We will use a &#39;FC&#39; layer as the main component of the model. Since we desire two weights ($\beta_2$ and $\beta_1$), we set our input dimension to 2, and since we only expect a single quantitative result, our output dimension is 1. Note, when using an &#39;FC&#39; layer it is implied that there is a bias, which we will use as our $\beta_0.$</span></div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;<span class="comment"># Also, before continuing take a look at the protobuf created in this step. The first print out is of the &#39;net,&#39; and contains the architecture of the model. At a glance, we see that as expected, there is a single op in the network that expects an input $X,$ a weight and bias, and outputs $y_{pred}.$ In the print out of the &#39;param_init_net,&#39; we see that this is where the initializations for the weights and biases exist. This is an important observation that gives insight into how a model in Caffe2 is constructed and maintained.</span></div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;<span class="comment"># In[4]:</span></div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;<span class="comment"># Create the model helper object we will use to create the regression model</span></div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;regression_model = ModelHelper(name=<span class="stringliteral">&quot;regression_model&quot;</span>)</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;<span class="comment"># Add the FC layer, which is the main component of a linear regression model</span></div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;y_pred = brew.fc(regression_model,<span class="stringliteral">&#39;X&#39;</span>,<span class="stringliteral">&#39;y_pred&#39;</span>, dim_in=2, dim_out=1)</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;<span class="comment"># Print the predict and init net to see what protobuf was created for this model</span></div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;print(<span class="stringliteral">&quot;************* Predict Net *************&quot;</span>)</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;print(regression_model.net.Proto())</div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;print(<span class="stringliteral">&quot;\n************* Init Net *************&quot;</span>)</div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;print(regression_model.param_init_net.Proto())</div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;</div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;</div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;<span class="comment"># #### Add the training operators and prime the workspace</span></div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;<span class="comment"># In this **very important** step, we specify the loss function, setup the SGD training algorithm, prime and initialize the workspace, and initialize our model&#39;s weights and biases.</span></div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;<span class="comment"># In[5]:</span></div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;<span class="comment"># The loss function is computed by a squared L2 distance, </span></div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;<span class="comment">#   and then averaged over all items.</span></div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;dist = regression_model.SquaredL2Distance([<span class="stringliteral">&#39;Y_gt&#39;</span>, y_pred], <span class="stringliteral">&quot;dist&quot;</span>)</div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;loss = regression_model.AveragedLoss(dist, <span class="stringliteral">&quot;loss&quot;</span>)</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;<span class="comment"># Add the gradient operators and setup the SGD algorithm</span></div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;regression_model.AddGradientOperators([loss])</div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;optimizer.build_sgd(regression_model, base_learning_rate=learning_rate)</div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;</div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;<span class="comment"># Prime the workspace with some data</span></div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;workspace.FeedBlob(<span class="stringliteral">&quot;Y_gt&quot;</span>,Y_gt.astype(np.float32))</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;workspace.FeedBlob(<span class="stringliteral">&quot;X&quot;</span>,X.astype(np.float32))</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;<span class="comment"># Run the init net to prepare the workspace then create the net</span></div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;workspace.RunNetOnce(regression_model.param_init_net)</div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;workspace.CreateNet(regression_model.net)</div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;</div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;<span class="comment"># Inject our desired initial weights and bias</span></div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;workspace.FeedBlob(<span class="stringliteral">&quot;y_pred_w&quot;</span>,np.array([initial_weights]).astype(np.float32))</div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;workspace.FeedBlob(<span class="stringliteral">&quot;y_pred_b&quot;</span>,np.array([0.]).astype(np.float32))</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;<span class="comment"># #### Run the training</span></div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;<span class="comment"># In[6]:</span></div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;<span class="comment"># Run the training for training_iters</span></div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;<span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(training_iters):</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;    workspace.RunNet(regression_model.net)</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;print(<span class="stringliteral">&quot;Training Complete&quot;</span>)</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;</div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;<span class="comment"># ### Extract Results</span></div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;<span class="comment"># Now that our model is trained, we can pull out the learned weights and biases which exist as blobs in the workspace named &#39;y_pred_w&#39; and &#39;y_pred_b.&#39;</span></div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;</div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;<span class="comment"># In[7]:</span></div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;<span class="comment"># Extract the learned coes and intercept from the workspace</span></div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;coes = workspace.FetchBlob(<span class="stringliteral">&quot;y_pred_w&quot;</span>)[0]</div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;intercept = workspace.FetchBlob(<span class="stringliteral">&quot;y_pred_b&quot;</span>)</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;<span class="comment"># Calculate the regression line for plotting</span></div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;x_vals = np.linspace(orig_X.min(), orig_X.max(),100)</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;regression_result = intercept[0] + coes[0]*x_vals + coes[1]*(x_vals**2)</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;print(<span class="stringliteral">&quot;Best Fit Line: {}*x^2 + {}*x + {}&quot;</span>.format(round(coes[1],5), round(coes[0],5), round(intercept[0],5)))</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;</div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;<span class="comment"># Plot the results of the regression</span></div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;plt.scatter([i[0] <span class="keywordflow">for</span> i <span class="keywordflow">in</span> X],Y_gt,label=<span class="stringliteral">&quot;original data&quot;</span>,color=<span class="stringliteral">&#39;b&#39;</span>)</div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;plt.plot(x_vals,regression_result,label=<span class="stringliteral">&quot;regression result&quot;</span>,color=<span class="stringliteral">&#39;r&#39;)</span></div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;<span class="stringliteral">plt.legend()</span></div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;<span class="stringliteral">plt.xlabel(&quot;x&quot;</span>)</div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;plt.ylabel(<span class="stringliteral">&quot;y&quot;</span>)</div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;plt.title(<span class="stringliteral">&quot;Polynomial Regression Fit: ${{{}}}x^2 + {{{}}}x + {{{}}}$&quot;</span>.format(round(coes[1],5), round(coes[0],5), round(intercept[0],5)))</div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;plt.show()</div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;</div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;</div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;<span class="comment"># ## Part II: Express Linear Regression Example</span></div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;<span class="comment"># The above example shows you how to create a polynomial regression model that is easily adapted to handle higher order polynomials. Now, we will consider the baseline case where we desire a simple first order model, with 1-D input $x,$ 1-D output $y,$ and a solution of the form:</span></div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;<span class="comment"># $$y = \beta_1x + \beta_0$$</span></div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;<span class="comment"># The structure of Part II will be similar to Part I. First, we will generate the dataset, then we will construct the model and specify the training routine, and finally we will train and extract our results.</span></div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;<span class="comment"># In[8]:</span></div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;</div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;</div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;<span class="comment">#####################################################################</span></div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;<span class="comment"># Initialize data</span></div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;<span class="comment">#####################################################################</span></div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;X,Y_gt = sklearn.datasets.make_regression(n_samples=100,n_features=1,noise=10)</div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;Y_gt = np.reshape(Y_gt,(-1,1))</div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;Y_gt /= 100.</div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;</div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;<span class="comment">#####################################################################</span></div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;<span class="comment"># Create and train model</span></div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;<span class="comment">#####################################################################</span></div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;<span class="comment"># Construct model with single FC layer</span></div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;regression_model = ModelHelper(name=<span class="stringliteral">&quot;regression_model&quot;</span>)</div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;y_pred = brew.fc(regression_model,<span class="stringliteral">&#39;X&#39;</span>,<span class="stringliteral">&#39;y_pred&#39;</span>, dim_in=1, dim_out=1)</div><div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;</div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;<span class="comment"># Specify Loss function</span></div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;dist = regression_model.SquaredL2Distance([<span class="stringliteral">&#39;Y_gt&#39;</span>, y_pred], <span class="stringliteral">&quot;dist&quot;</span>)</div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;loss = regression_model.AveragedLoss(dist, <span class="stringliteral">&quot;loss&quot;</span>)</div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;</div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;<span class="comment"># Get gradients for all the computations above.</span></div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;regression_model.AddGradientOperators([loss])</div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;optimizer.build_sgd(regression_model, base_learning_rate=0.05)</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;</div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;<span class="comment"># Prime and prepare workspace for training</span></div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;workspace.FeedBlob(<span class="stringliteral">&quot;Y_gt&quot;</span>,Y_gt.astype(np.float32))</div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;workspace.FeedBlob(<span class="stringliteral">&quot;X&quot;</span>,X.astype(np.float32))</div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;workspace.RunNetOnce(regression_model.param_init_net)</div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;workspace.CreateNet(regression_model.net)</div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;</div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;<span class="comment"># Set the initial weight and bias to 0</span></div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;workspace.FeedBlob(<span class="stringliteral">&quot;y_pred_w&quot;</span>,np.array([[0.]]).astype(np.float32))</div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;workspace.FeedBlob(<span class="stringliteral">&quot;y_pred_b&quot;</span>,np.array([0.]).astype(np.float32))</div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;</div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;<span class="comment"># Train the model</span></div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;<span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(100):</div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;    workspace.RunNet(regression_model.net)</div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;</div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;<span class="comment">#####################################################################</span></div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;<span class="comment"># Collect and format results</span></div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;<span class="comment">#####################################################################</span></div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;<span class="comment"># Grab the learned weight and bias from workspace</span></div><div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;coe = workspace.FetchBlob(<span class="stringliteral">&quot;y_pred_w&quot;</span>)[0]</div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;intercept = workspace.FetchBlob(<span class="stringliteral">&quot;y_pred_b&quot;</span>)</div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;</div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;<span class="comment"># Calculate the regression line for plotting</span></div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;x_vals = range(-3,4)</div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;regression_result = x_vals*coe + intercept</div><div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;</div><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;<span class="comment"># Plot the results</span></div><div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;plt.scatter(X,Y_gt,label=<span class="stringliteral">&quot;original data&quot;</span>,color=<span class="stringliteral">&#39;b&#39;</span>)</div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;plt.plot(x_vals,regression_result,label=<span class="stringliteral">&quot;regression result&quot;</span>,color=<span class="stringliteral">&#39;r&#39;)</span></div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;<span class="stringliteral">plt.legend()</span></div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;<span class="stringliteral">plt.xlabel(&quot;x&quot;</span>)</div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;plt.ylabel(<span class="stringliteral">&quot;y&quot;</span>)</div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;plt.title(<span class="stringliteral">&quot;Regression Line: ${{{}}}x + {{{}}}$&quot;</span>.format(round(coe,5), round(intercept[0],5)))</div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;plt.show()</div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;</div><div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;</div><div class="ttc" id="namespacecaffe2_1_1python_html"><div class="ttname"><a href="namespacecaffe2_1_1python.html">caffe2.python</a></div><div class="ttdef"><b>Definition:</b> <a href="python_2____init_____8py_source.html#l00001">__init__.py:1</a></div></div>
<div class="ttc" id="namespacecaffe2_1_1python_1_1model__helper_html"><div class="ttname"><a href="namespacecaffe2_1_1python_1_1model__helper.html">caffe2.python.model_helper</a></div><div class="ttdef"><b>Definition:</b> <a href="model__helper_8py_source.html#l00001">model_helper.py:1</a></div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- HTML footer for doxygen 1.8.14-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Sun Mar 25 2018 13:03:35 for Caffe2 - Python API by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
<div class="footerContainer">
  <div id="footer_wrap" class="wrapper footerWrapper">
    <div class="footerBlocks">
      <div id="fb_oss" class="footerSection fbOpenSourceFooter">
          <svg class="facebookOSSLogoSvg" viewBox="0 0 1133.9 1133.9" x="0px" y="0px" height=50 width=50>
            <g>
              <path class="logoRing outerRing" d="M 498.3 3.7 c 153.6 88.9 307.3 177.7 461.1 266.2 c 7.6 4.4 10.3 9.1 10.3 17.8 c -0.3 179.1 -0.2 358.3 0 537.4 c 0 8.1 -2.4 12.8 -9.7 17.1 c -154.5 88.9 -308.8 178.1 -462.9 267.5 c -9 5.2 -15.5 5.3 -24.6 0.1 c -153.9 -89.2 -307.9 -178 -462.1 -266.8 C 3 838.8 0 833.9 0 825.1 c 0.3 -179.1 0.2 -358.3 0 -537.4 c 0 -8.6 2.6 -13.6 10.2 -18 C 164.4 180.9 318.4 92 472.4 3 C 477 -1.5 494.3 -0.7 498.3 3.7 Z M 48.8 555.3 c 0 79.9 0.2 159.9 -0.2 239.8 c -0.1 10 3 15.6 11.7 20.6 c 137.2 78.8 274.2 157.8 411 237.3 c 9.9 5.7 17 5.7 26.8 0.1 c 137.5 -79.8 275.2 -159.2 412.9 -238.5 c 7.4 -4.3 10.5 -8.9 10.5 -17.8 c -0.3 -160.2 -0.3 -320.5 0 -480.7 c 0 -8.8 -2.8 -13.6 -10.3 -18 C 772.1 218 633.1 137.8 494.2 57.4 c -6.5 -3.8 -11.5 -4.5 -18.5 -0.5 C 336.8 137.4 197.9 217.7 58.8 297.7 c -7.7 4.4 -10.2 9.2 -10.2 17.9 C 48.9 395.5 48.8 475.4 48.8 555.3 Z" />
              <path class="logoRing middleRing" d="M 184.4 555.9 c 0 -33.3 -1 -66.7 0.3 -100 c 1.9 -48 24.1 -86 64.7 -110.9 c 54.8 -33.6 110.7 -65.5 167 -96.6 c 45.7 -25.2 92.9 -24.7 138.6 1 c 54.4 30.6 108.7 61.5 162.2 93.7 c 44 26.5 67.3 66.8 68 118.4 c 0.9 63.2 0.9 126.5 0 189.7 c -0.7 50.6 -23.4 90.7 -66.6 116.9 c -55 33.4 -110.8 65.4 -167.1 96.5 c -43.4 24 -89 24.2 -132.3 0.5 c -57.5 -31.3 -114.2 -64 -170 -98.3 c -41 -25.1 -62.9 -63.7 -64.5 -112.2 C 183.5 621.9 184.3 588.9 184.4 555.9 Z M 232.9 556.3 c 0 29.5 0.5 59.1 -0.1 88.6 c -0.8 39.2 16.9 67.1 50.2 86.2 c 51.2 29.4 102.2 59.2 153.4 88.4 c 31.4 17.9 63.6 18.3 95 0.6 c 53.7 -30.3 107.1 -61.2 160.3 -92.5 c 29.7 -17.5 45 -44.5 45.3 -78.8 c 0.6 -61.7 0.5 -123.5 0 -185.2 c -0.3 -34.4 -15.3 -61.5 -44.9 -79 C 637.7 352.6 583 320.8 527.9 290 c -27.5 -15.4 -57.2 -16.1 -84.7 -0.7 c -56.9 31.6 -113.4 64 -169.1 97.6 c -26.4 15.9 -40.7 41.3 -41.1 72.9 C 232.6 491.9 232.9 524.1 232.9 556.3 Z" />
              <path class="logoRing innerRing" d="M 484.9 424.4 c 69.8 -2.8 133.2 57.8 132.6 132 C 617 630 558.5 688.7 484.9 689.1 c -75.1 0.4 -132.6 -63.6 -132.7 -132.7 C 352.1 485 413.4 421.5 484.9 424.4 Z M 401.3 556.7 c -3.4 37.2 30.5 83.6 83 84.1 c 46.6 0.4 84.8 -37.6 84.9 -84 c 0.1 -46.6 -37.2 -84.4 -84.2 -84.6 C 432.2 472.1 397.9 518.3 401.3 556.7 Z" />
            </g>
          </svg>
        <h2>Facebook Open Source</h2>
      </div>
      <div class="footerSection">
        <a class="footerLink" href="https://code.facebook.com/projects/" target="_blank">Open Source Projects</a>
        <a class="footerLink" href="https://github.com/facebook/" target="_blank">GitHub</a>
        <a class="footerLink" href="https://twitter.com/fbOpenSource" target="_blank">Twitter</a>
      </div>
      <div class="footerSection rightAlign">
        <a class="footerLink" href="https://github.com/caffe2/caffe2" target="_blank">Contribute to this project on GitHub</a>
      </div>
    </div>
  </div>
</div>
<script type="text/javascript" src="/js/jekyll-link-anchors.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', '{{ site.gacode }}', 'auto');
  ga('send', 'pageview');
</script>
</body>
</html>
